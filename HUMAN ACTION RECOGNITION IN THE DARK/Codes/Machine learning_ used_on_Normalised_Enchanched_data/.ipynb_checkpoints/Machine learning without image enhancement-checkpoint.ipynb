{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3952fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64cf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Function to extract features from frames using InceptionV3\n",
    "def extract_features(frames):\n",
    "    # Load InceptionV3 model (excluding top layers)\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
    "    \n",
    "    # Resize frames to 299x299 (required input size for InceptionV3)\n",
    "    resized_frames = [cv2.resize(frame, (299, 299)) for frame in frames]\n",
    "    \n",
    "    # Preprocess frames\n",
    "    preprocessed_frames = preprocess_input(np.array(resized_frames))\n",
    "    \n",
    "    # Extract features using InceptionV3\n",
    "    features = base_model.predict(preprocessed_frames)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Function to preprocess video frames\n",
    "def preprocess_frames(frames):\n",
    "    # Normalize frames\n",
    "    reference_mean = np.array([0.07, 0.07, 0.07])\n",
    "    reference_std = np.array([0.1, 0.09, 0.08])\n",
    "    frames_normalized = [(frame.astype(np.float32) - reference_mean) / reference_std for frame in frames]\n",
    "    \n",
    "    return frames_normalized\n",
    "\n",
    "# Function to process video\n",
    "def process_video(video_path, max_frames=20):\n",
    "    # Read video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate sampling interval\n",
    "    sampling_interval = max(1, frame_count // max_frames)\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frames.append(frame)\n",
    "        # Skip frames based on sampling interval\n",
    "        for _ in range(sampling_interval - 1):\n",
    "            cap.grab()\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Pad frames if necessary\n",
    "    if len(frames) < max_frames:\n",
    "        frames.extend([frames[-1]] * (max_frames - len(frames)))\n",
    "    \n",
    "    # Preprocess frames\n",
    "    preprocessed_frames = preprocess_frames(frames)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(preprocessed_frames)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb38b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "features = []\n",
    "labels = []\n",
    "# Test\n",
    "features_1 = []\n",
    "labels_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfd2df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos for training: 150\n",
      "Total videos for testing: 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/test/Walk/296.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/test/Walk/309.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>data/test/Walk/308.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>data/test/Walk/297.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>data/test/Walk/295.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>data/test/Walk/300.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>data/test/Walk/301.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>data/test/Walk/303.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>data/test/Walk/302.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>data/test/Walk/299.mp4</td>\n",
       "      <td>Walk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              video_name   tag\n",
       "0           0  data/test/Walk/296.mp4  Walk\n",
       "1           1  data/test/Walk/309.mp4  Walk\n",
       "2           2  data/test/Walk/308.mp4  Walk\n",
       "3           3  data/test/Walk/297.mp4  Walk\n",
       "4           4  data/test/Walk/295.mp4  Walk\n",
       "5           5  data/test/Walk/300.mp4  Walk\n",
       "6           6  data/test/Walk/301.mp4  Walk\n",
       "7           7  data/test/Walk/303.mp4  Walk\n",
       "8           8  data/test/Walk/302.mp4  Walk\n",
       "9           9  data/test/Walk/299.mp4  Walk"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2a89be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jump', 'Run', 'Sit', 'Stand', 'Turn', 'Walk']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels = train_df[\"tag\"].values\n",
    "labels = label_processor(labels[..., None]).numpy()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd2149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values: 6\n",
      "Frequency of each unique value:\n",
      "(5,): 25\n",
      "(2,): 25\n",
      "(0,): 25\n",
      "(4,): 25\n",
      "(3,): 25\n",
      "(1,): 25\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter  # Import Counter class\n",
    "# Convert NumPy arrays to tuples\n",
    "my_list_tuples = [tuple(x) for x in labels]\n",
    "\n",
    "# Count the frequency of each element in the list\n",
    "counter = Counter(my_list_tuples)\n",
    "\n",
    "unique_count = len(counter)  # Get the count of unique values\n",
    "\n",
    "print(\"Number of unique values:\", unique_count)\n",
    "\n",
    "print(\"Frequency of each unique value:\")\n",
    "for value, frequency in counter.items():\n",
    "    print(f\"{value}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f486c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2947a20c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x286743ec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "\n",
    "for videos in train_df['video_name']:\n",
    "    video_path = videos\n",
    "    video_features = process_video(video_path)\n",
    "    features.append(video_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9d3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jump', 'Run', 'Sit', 'Stand', 'Turn', 'Walk']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(test_df[\"tag\"]))\n",
    "print(label_processor.get_vocabulary())\n",
    "\n",
    "labels_1 = test_df[\"tag\"].values\n",
    "labels_1 = label_processor(labels_1[..., None]).numpy()\n",
    "labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e5067b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values: 6\n",
      "Frequency of each unique value:\n",
      "(5,): 16\n",
      "(2,): 15\n",
      "(0,): 17\n",
      "(4,): 17\n",
      "(3,): 16\n",
      "(1,): 15\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter  # Import Counter class\n",
    "# Convert NumPy arrays to tuples\n",
    "my_list_tuples = [tuple(x) for x in labels_1]\n",
    "\n",
    "# Count the frequency of each element in the list\n",
    "counter = Counter(my_list_tuples)\n",
    "\n",
    "unique_count = len(counter)  # Get the count of unique values\n",
    "\n",
    "print(\"Number of unique values:\", unique_count)\n",
    "\n",
    "print(\"Frequency of each unique value:\")\n",
    "for value, frequency in counter.items():\n",
    "    print(f\"{value}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06847465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 3s 308ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 3s 97ms/step\n",
      "2/2 [==============================] - 4s 287ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 295ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for videos in test_df['video_name']:\n",
    "    video_path = videos\n",
    "    video_features = process_video(video_path)\n",
    "    features_1.append(video_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c258db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features:\n",
      "150\n",
      "train labels:\n",
      "150\n",
      "test features:\n",
      "96\n",
      "test labels:\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print('train features:')\n",
    "print(len(features))\n",
    "print('train labels:')\n",
    "print(len(labels))\n",
    "\n",
    "print('test features:')\n",
    "print(len(features_1))\n",
    "print('test labels:')\n",
    "print(len(labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef674b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features\n",
    "\n",
    "y_train = labels\n",
    "X_test = features_1\n",
    "y_test = labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f1f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad feature vectors to ensure consistent length\n",
    "padded_feature_vectors = pad_sequences(X_train, maxlen= 29, padding='post', dtype='float32')\n",
    "\n",
    "padded_feature_vectors_1 = pad_sequences(X_test, maxlen= 29, padding='post', dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ae7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = padded_feature_vectors\n",
    "X_test = padded_feature_vectors_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd2337a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca105a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshua/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Train SVC classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train_flattened, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = clf.predict(X_test_flattened)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b7346bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 2048)\n",
      "(25, 2048)\n",
      "(23, 2048)\n",
      "(25, 2048)\n",
      "(24, 2048)\n",
      "(23, 2048)\n",
      "(27, 2048)\n",
      "(25, 2048)\n",
      "(22, 2048)\n",
      "(20, 2048)\n",
      "(20, 2048)\n",
      "(27, 2048)\n",
      "(27, 2048)\n",
      "(28, 2048)\n",
      "(29, 2048)\n",
      "(29, 2048)\n",
      "(26, 2048)\n",
      "(22, 2048)\n",
      "(24, 2048)\n",
      "(24, 2048)\n",
      "(21, 2048)\n",
      "(25, 2048)\n",
      "(21, 2048)\n",
      "(20, 2048)\n",
      "(22, 2048)\n",
      "(24, 2048)\n",
      "(26, 2048)\n",
      "(27, 2048)\n",
      "(26, 2048)\n",
      "(26, 2048)\n",
      "(21, 2048)\n",
      "(29, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(20, 2048)\n",
      "(27, 2048)\n",
      "(23, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(26, 2048)\n",
      "(21, 2048)\n",
      "(29, 2048)\n",
      "(26, 2048)\n",
      "(23, 2048)\n",
      "(24, 2048)\n",
      "(23, 2048)\n",
      "(22, 2048)\n",
      "(24, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(26, 2048)\n",
      "(22, 2048)\n",
      "(26, 2048)\n",
      "(22, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(21, 2048)\n",
      "(29, 2048)\n",
      "(24, 2048)\n",
      "(26, 2048)\n",
      "(28, 2048)\n",
      "(29, 2048)\n",
      "(23, 2048)\n",
      "(23, 2048)\n",
      "(20, 2048)\n",
      "(29, 2048)\n",
      "(29, 2048)\n",
      "(27, 2048)\n",
      "(22, 2048)\n",
      "(22, 2048)\n",
      "(39, 2048)\n",
      "(25, 2048)\n",
      "(24, 2048)\n",
      "(35, 2048)\n",
      "(36, 2048)\n",
      "(37, 2048)\n",
      "(39, 2048)\n",
      "(22, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(23, 2048)\n",
      "(27, 2048)\n",
      "(22, 2048)\n",
      "(25, 2048)\n",
      "(22, 2048)\n",
      "(39, 2048)\n",
      "(25, 2048)\n",
      "(22, 2048)\n",
      "(34, 2048)\n",
      "(38, 2048)\n",
      "(25, 2048)\n",
      "(34, 2048)\n",
      "(23, 2048)\n",
      "(38, 2048)\n",
      "(33, 2048)\n",
      "(26, 2048)\n",
      "(20, 2048)\n",
      "(22, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(24, 2048)\n",
      "(26, 2048)\n",
      "(26, 2048)\n",
      "(23, 2048)\n",
      "(25, 2048)\n",
      "(30, 2048)\n",
      "(27, 2048)\n",
      "(22, 2048)\n",
      "(23, 2048)\n",
      "(21, 2048)\n",
      "(23, 2048)\n",
      "(25, 2048)\n",
      "(22, 2048)\n",
      "(23, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(26, 2048)\n",
      "(29, 2048)\n",
      "(27, 2048)\n",
      "(23, 2048)\n",
      "(21, 2048)\n",
      "(25, 2048)\n",
      "(22, 2048)\n",
      "(26, 2048)\n",
      "(28, 2048)\n",
      "(21, 2048)\n",
      "(24, 2048)\n",
      "(25, 2048)\n",
      "(27, 2048)\n",
      "(26, 2048)\n",
      "(26, 2048)\n",
      "(21, 2048)\n",
      "(26, 2048)\n",
      "(21, 2048)\n",
      "(28, 2048)\n",
      "(22, 2048)\n",
      "(29, 2048)\n",
      "(21, 2048)\n",
      "(23, 2048)\n",
      "(21, 2048)\n",
      "(22, 2048)\n",
      "(27, 2048)\n",
      "(23, 2048)\n",
      "(22, 2048)\n",
      "(21, 2048)\n",
      "(21, 2048)\n",
      "(29, 2048)\n"
     ]
    }
   ],
   "source": [
    "for feature_vector in X_train:\n",
    "    print(feature_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79c465d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234630 (916.52 KB)\n",
      "Trainable params: 234630 (916.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Define the MLP model\n",
    "def create_mlp(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Flatten layer to convert 2D feature maps into a 1D feature vector\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    # Output layer with softmax activation for classification\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (28, 28, 1)  # Example input shape (adjust based on your CNN output shape)\n",
    "num_classes = 6  # Example number of classes (adjust based on your classification task)\n",
    "\n",
    "# Create the MLP model\n",
    "mlp_model = create_mlp(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "mlp_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc60ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
